{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Classification with AKOrN (Artificial Kuramoto Oscillator Networks)\n",
    "\n",
    "This notebook demonstrates how to train an AKOrN model for CIFAR-10 image classification.\n",
    "AKOrN is based on the dynamics of Kuramoto oscillators and provides an alternative to traditional neural networks.\n",
    "\n",
    "## References\n",
    "- Miyato et al., \"Artificial Kuramoto Oscillatory Neurons\", ICLR 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "%sys.path.append(\"/work/gj26/b20109/akorn/source\")\n",
    "\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# Add source directory to path\n",
    "#sys.path.append('source')\n",
    "\n",
    "from models.classification.knet import AKOrN\n",
    "from data.augs import augmentation_strong\n",
    "from training_utils import save_checkpoint, save_model\n",
    "from utils import str2bool\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Imports completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    # Data\n",
    "    'batch_size': 128,\n",
    "    'num_workers': 4,\n",
    "    'num_classes': 10,\n",
    "    \n",
    "    # Model architecture\n",
    "    'n': 2,              # Oscillator dimension (2D for complex oscillators)\n",
    "    'ch': 64,            # Base number of channels\n",
    "    'L': 3,              # Number of layers\n",
    "    'T': 3,              # Number of time steps per layer\n",
    "    'gamma': 1.0,        # Integration step size\n",
    "    'J': 'conv',         # Connectivity type ('conv' or 'attn')\n",
    "    'ksizes': [9, 7, 5], # Kernel sizes for each layer\n",
    "    'ro_ksize': 3,       # Readout kernel size\n",
    "    'ro_N': 2,           # Readout N parameter\n",
    "    'norm': 'bn',        # Normalization type\n",
    "    'c_norm': 'gn',      # C normalization type\n",
    "    'use_omega': True,   # Use natural frequencies\n",
    "    'init_omg': 1.0,     # Initial omega value\n",
    "    'global_omg': True,  # Global omega parameter\n",
    "    'learn_omg': True,   # Learn omega parameters\n",
    "    'ensemble': 1,       # Ensemble size\n",
    "    \n",
    "    # Training\n",
    "    'epochs': 100,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 0.0,\n",
    "    'warmup_epochs': 5,\n",
    "    \n",
    "    # Logging\n",
    "    'log_interval': 100,\n",
    "    'eval_interval': 5,\n",
    "    'save_interval': 20,\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms\n",
    "transform_train = augmentation_strong(imsize=32)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = CIFAR10(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "test_dataset = CIFAR10(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform_test\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config['batch_size'], \n",
    "    shuffle=True, \n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=config['batch_size'], \n",
    "    shuffle=False, \n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# CIFAR-10 class names\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Classes: {classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize samples\n",
    "def visualize_samples(dataset, num_samples=16, title=\"CIFAR-10 Samples\"):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        img, label = dataset[i]\n",
    "        \n",
    "        # Convert tensor to numpy and transpose for visualization\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img_np = img.permute(1, 2, 0).numpy()\n",
    "            # Denormalize if needed\n",
    "            img_np = np.clip(img_np, 0, 1)\n",
    "        else:\n",
    "            img_np = np.array(img) / 255.0\n",
    "        \n",
    "        ax = axes[i // 4, i % 4]\n",
    "        ax.imshow(img_np)\n",
    "        ax.set_title(f'{classes[label]}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize training samples\n",
    "visualize_samples(test_dataset, title=\"CIFAR-10 Test Samples\")\n",
    "\n",
    "# Plot class distribution\n",
    "def plot_class_distribution(dataset, title=\"Class Distribution\"):\n",
    "    labels = [dataset[i][1] for i in range(len(dataset))]\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar([classes[i] for i in unique], counts)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 50,\n",
    "                f'{count}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_class_distribution(train_dataset, \"Training Set Class Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AKOrN model\n",
    "model = AKOrN(\n",
    "    n=config['n'],\n",
    "    ch=config['ch'],\n",
    "    out_classes=config['num_classes'],\n",
    "    L=config['L'],\n",
    "    T=config['T'],\n",
    "    J=config['J'],\n",
    "    ksizes=config['ksizes'],\n",
    "    ro_ksize=config['ro_ksize'],\n",
    "    ro_N=config['ro_N'],\n",
    "    norm=config['norm'],\n",
    "    c_norm=config['c_norm'],\n",
    "    gamma=config['gamma'],\n",
    "    use_omega=config['use_omega'],\n",
    "    init_omg=config['init_omg'],\n",
    "    global_omg=config['global_omg'],\n",
    "    learn_omg=config['learn_omg'],\n",
    "    ensemble=config['ensemble'],\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model created successfully!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: {total_params * 4 / 1e6:.2f} MB (float32)\")\n",
    "\n",
    "# Print model architecture\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=config['lr'], \n",
    "    weight_decay=config['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=config['epochs'],\n",
    "    eta_min=config['lr'] * 0.01\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"Learning rate: {config['lr']}\")\n",
    "print(f\"Scheduler: {scheduler.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        if batch_idx % config['log_interval'] == 0:\n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc='Evaluating'):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            \n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "            \n",
    "            # Per-class accuracy\n",
    "            c = (predicted == target).squeeze()\n",
    "            for i in range(target.size(0)):\n",
    "                label = target[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = 100. * correct / total\n",
    "    \n",
    "    # Per-class accuracies\n",
    "    class_accuracies = {}\n",
    "    for i in range(10):\n",
    "        if class_total[i] > 0:\n",
    "            class_accuracies[classes[i]] = 100 * class_correct[i] / class_total[i]\n",
    "        else:\n",
    "            class_accuracies[classes[i]] = 0\n",
    "    \n",
    "    return test_loss, test_acc, class_accuracies\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, filename):\n",
    "    \"\"\"Save model checkpoint\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'config': config\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved: {filename}\")\n",
    "\n",
    "print(\"Training and evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'test_loss': [],\n",
    "    'test_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_acc = 0\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Training for {config['epochs']} epochs\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, epoch\n",
    "    )\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Evaluate\n",
    "    if (epoch + 1) % config['eval_interval'] == 0:\n",
    "        test_loss, test_acc, class_accs = evaluate(model, test_loader, criterion, device)\n",
    "        \n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{config['epochs']}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "        print(f\"  Learning Rate: {current_lr:.6f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            save_checkpoint(\n",
    "                model, optimizer, epoch, test_loss, \n",
    "                f'best_model_acc_{best_acc:.2f}.pth'\n",
    "            )\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # Save periodic checkpoint\n",
    "    if (epoch + 1) % config['save_interval'] == 0:\n",
    "        save_checkpoint(\n",
    "            model, optimizer, epoch, train_loss,\n",
    "            f'checkpoint_epoch_{epoch+1}.pth'\n",
    "        )\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {total_time/3600:.2f} hours\")\n",
    "print(f\"Best test accuracy: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "print(\"Final Evaluation:\")\n",
    "final_test_loss, final_test_acc, final_class_accs = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n",
    "print(f\"Final Test Loss: {final_test_loss:.4f}\")\n",
    "\n",
    "# Per-class accuracies\n",
    "print(\"\\nPer-class Accuracies:\")\n",
    "for class_name, acc in final_class_accs.items():\n",
    "    print(f\"  {class_name}: {acc:.2f}%\")\n",
    "\n",
    "# Plot per-class accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_names = list(final_class_accs.keys())\n",
    "accuracies = list(final_class_accs.values())\n",
    "bars = plt.bar(class_names, accuracies)\n",
    "plt.title('Per-Class Accuracy')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 1,\n",
    "            f'{acc:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "if history['test_loss']:\n",
    "    eval_epochs = list(range(config['eval_interval']-1, len(history['train_loss']), config['eval_interval']))\n",
    "    axes[0, 0].plot(eval_epochs, history['test_loss'], label='Test Loss', linewidth=2, marker='o')\n",
    "axes[0, 0].set_title('Loss Over Time')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.7)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0, 1].plot(history['train_acc'], label='Train Accuracy', linewidth=2)\n",
    "if history['test_acc']:\n",
    "    axes[0, 1].plot(eval_epochs, history['test_acc'], label='Test Accuracy', linewidth=2, marker='o')\n",
    "axes[0, 1].set_title('Accuracy Over Time')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.7)\n",
    "\n",
    "# Learning rate plot\n",
    "axes[1, 0].plot(history['lr'], linewidth=2, color='orange')\n",
    "axes[1, 0].set_title('Learning Rate Schedule')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].set_yscale('log')\n",
    "axes[1, 0].grid(True, alpha=0.7)\n",
    "\n",
    "# Training summary\n",
    "axes[1, 1].axis('off')\n",
    "summary_text = f\"\"\"\n",
    "Training Summary:\n",
    "• Total epochs: {len(history['train_loss'])}\n",
    "• Best test accuracy: {best_acc:.2f}%\n",
    "• Final test accuracy: {final_test_acc:.2f}%\n",
    "• Total parameters: {total_params:,}\n",
    "• Training time: {total_time/3600:.2f} hours\n",
    "\n",
    "Model Configuration:\n",
    "• Oscillator dimension (n): {config['n']}\n",
    "• Base channels: {config['ch']}\n",
    "• Number of layers: {config['L']}\n",
    "• Time steps per layer: {config['T']}\n",
    "• Connectivity: {config['J']}\n",
    "• Kernel sizes: {config['ksizes']}\n",
    "\"\"\"\n",
    "axes[1, 1].text(0.1, 0.9, summary_text, transform=axes[1, 1].transAxes, \n",
    "               fontsize=11, verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model predictions\n",
    "def analyze_predictions(model, test_loader, device, num_samples=16):\n",
    "    \"\"\"Analyze model predictions with visualization\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of test data\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "    \n",
    "    # Visualize predictions\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "    fig.suptitle('Model Predictions Analysis', fontsize=16)\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        ax = axes[i // 4, i % 4]\n",
    "        \n",
    "        # Convert image to displayable format\n",
    "        img = images[i].cpu().permute(1, 2, 0)\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        \n",
    "        # Get prediction info\n",
    "        true_label = labels[i].item()\n",
    "        pred_label = predicted[i].item()\n",
    "        confidence = probabilities[i][pred_label].item()\n",
    "        \n",
    "        # Color code: green for correct, red for incorrect\n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        \n",
    "        ax.set_title(f'True: {classes[true_label]}\\nPred: {classes[pred_label]}\\nConf: {confidence:.3f}', \n",
    "                    color=color, fontsize=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return images, labels, predicted, probabilities\n",
    "\n",
    "# Analyze predictions\n",
    "sample_images, sample_labels, sample_preds, sample_probs = analyze_predictions(\n",
    "    model, test_loader, device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate predictions for entire test set\n",
    "def get_all_predictions(model, test_loader, device):\n",
    "    \"\"\"Get predictions for entire test set\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc='Getting predictions'):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(target.numpy())\n",
    "    \n",
    "    return np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "# Get all predictions\n",
    "true_labels, pred_labels = get_all_predictions(model, test_loader, device)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, pred_labels, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Model Dynamics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize AKOrN dynamics (energy and states over time)\n",
    "def visualize_akorn_dynamics(model, sample_image, device):\n",
    "    \"\"\"Visualize the dynamics of AKOrN during inference\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get intermediate states and energies\n",
    "    with torch.no_grad():\n",
    "        sample_image = sample_image.unsqueeze(0).to(device)\n",
    "        logits, xs, es = model(sample_image, return_xs=True, return_es=True)\n",
    "    \n",
    "    # Plot energy evolution\n",
    "    fig, axes = plt.subplots(2, len(es), figsize=(4*len(es), 8))\n",
    "    if len(es) == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    \n",
    "    for layer_idx, (layer_xs, layer_es) in enumerate(zip(xs, es)):\n",
    "        # Energy plot\n",
    "        energies = [e.cpu().numpy()[0] for e in layer_es]  # First sample in batch\n",
    "        axes[0, layer_idx].plot(energies, 'o-', linewidth=2, markersize=6)\n",
    "        axes[0, layer_idx].set_title(f'Layer {layer_idx+1} Energy')\n",
    "        axes[0, layer_idx].set_xlabel('Time Step')\n",
    "        axes[0, layer_idx].set_ylabel('Energy')\n",
    "        axes[0, layer_idx].grid(True, alpha=0.7)\n",
    "        \n",
    "        # State norm evolution\n",
    "        state_norms = [torch.norm(x[0]).cpu().item() for x in layer_xs]  # First sample\n",
    "        axes[1, layer_idx].plot(state_norms, 's-', linewidth=2, markersize=6, color='orange')\n",
    "        axes[1, layer_idx].set_title(f'Layer {layer_idx+1} State Norm')\n",
    "        axes[1, layer_idx].set_xlabel('Time Step')\n",
    "        axes[1, layer_idx].set_ylabel('||x||')\n",
    "        axes[1, layer_idx].grid(True, alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return logits, xs, es\n",
    "\n",
    "# Visualize dynamics for a sample image\n",
    "sample_idx = 0\n",
    "sample_img = sample_images[sample_idx]\n",
    "sample_label = sample_labels[sample_idx]\n",
    "\n",
    "print(f\"Analyzing dynamics for image with label: {classes[sample_label]}\")\n",
    "logits, states, energies = visualize_akorn_dynamics(model, sample_img, device)\n",
    "\n",
    "# Show prediction confidence\n",
    "probs = F.softmax(logits, dim=1)[0]\n",
    "print(f\"\\nPrediction probabilities:\")\n",
    "for i, (class_name, prob) in enumerate(zip(classes, probs)):\n",
    "    print(f\"  {class_name}: {prob:.4f}\")\n",
    "    \n",
    "predicted_class = torch.argmax(logits, dim=1)[0]\n",
    "print(f\"\\nPredicted class: {classes[predicted_class]} (confidence: {probs[predicted_class]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save Final Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "results_dir = Path('./results')\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save final model\n",
    "final_model_path = results_dir / 'akorn_cifar10_final.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'config': config,\n",
    "    'history': history,\n",
    "    'final_accuracy': final_test_acc,\n",
    "    'best_accuracy': best_acc,\n",
    "    'class_accuracies': final_class_accs\n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"Final model saved to: {final_model_path}\")\n",
    "\n",
    "# Save training history as CSV\n",
    "import pandas as pd\n",
    "\n",
    "# Pad test metrics to match training length\n",
    "test_loss_padded = []\n",
    "test_acc_padded = []\n",
    "for i in range(len(history['train_loss'])):\n",
    "    if i % config['eval_interval'] == config['eval_interval'] - 1 and i // config['eval_interval'] < len(history['test_loss']):\n",
    "        test_loss_padded.append(history['test_loss'][i // config['eval_interval']])\n",
    "        test_acc_padded.append(history['test_acc'][i // config['eval_interval']])\n",
    "    else:\n",
    "        test_loss_padded.append(None)\n",
    "        test_acc_padded.append(None)\n",
    "\n",
    "history_df = pd.DataFrame({\n",
    "    'epoch': range(1, len(history['train_loss']) + 1),\n",
    "    'train_loss': history['train_loss'],\n",
    "    'train_acc': history['train_acc'],\n",
    "    'test_loss': test_loss_padded,\n",
    "    'test_acc': test_acc_padded,\n",
    "    'learning_rate': history['lr']\n",
    "})\n",
    "\n",
    "history_path = results_dir / 'training_history.csv'\n",
    "history_df.to_csv(history_path, index=False)\n",
    "print(f\"Training history saved to: {history_path}\")\n",
    "\n",
    "# Save final results summary\n",
    "results_summary = {\n",
    "    'model': 'AKOrN',\n",
    "    'dataset': 'CIFAR-10',\n",
    "    'final_test_accuracy': final_test_acc,\n",
    "    'best_test_accuracy': best_acc,\n",
    "    'total_parameters': total_params,\n",
    "    'trainable_parameters': trainable_params,\n",
    "    'training_time_hours': total_time / 3600,\n",
    "    'epochs_trained': len(history['train_loss']),\n",
    "    'config': config\n",
    "}\n",
    "\n",
    "import json\n",
    "results_summary_path = results_dir / 'results_summary.json'\n",
    "with open(results_summary_path, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "    \n",
    "print(f\"Results summary saved to: {results_summary_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n",
    "print(f\"Best Test Accuracy: {best_acc:.2f}%\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Training Time: {total_time/3600:.2f} hours\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
